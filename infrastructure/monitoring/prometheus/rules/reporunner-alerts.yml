groups:
  - name: klikkflow.application
    rules:
      # Application Health Alerts
      - alert: KlikkFlowBackendDown
        expr: up{job="klikkflow-backend"} == 0
        for: 1m
        labels:
          severity: critical
          service: klikkflow-backend
        annotations:
          summary: "KlikkFlow Backend is down"
          description: "KlikkFlow Backend has been down for more than 1 minute"
          runbook_url: "https://docs.klikkflow.com/runbooks/backend-down"

      - alert: KlikkFlowFrontendDown
        expr: up{job="klikkflow-frontend"} == 0
        for: 2m
        labels:
          severity: warning
          service: klikkflow-frontend
        annotations:
          summary: "KlikkFlow Frontend is down"
          description: "KlikkFlow Frontend has been down for more than 2 minutes"

      - alert: KlikkFlowWorkerDown
        expr: up{job="klikkflow-workers"} == 0
        for: 1m
        labels:
          severity: critical
          service: klikkflow-workers
        annotations:
          summary: "KlikkFlow Worker is down"
          description: "At least one KlikkFlow Worker has been down for more than 1 minute"

      # Performance Alerts
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="klikkflow-backend"}[5m])) by (le)) > 2
        for: 5m
        labels:
          severity: warning
          service: klikkflow-backend
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s for the last 5 minutes"

      - alert: HighErrorRate
        expr: sum(rate(http_requests_total{job="klikkflow-backend",code=~"5.."}[5m])) / sum(rate(http_requests_total{job="klikkflow-backend"}[5m])) > 0.05
        for: 5m
        labels:
          severity: critical
          service: klikkflow-backend
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"

      # Workflow Execution Alerts
      - alert: WorkflowExecutionFailureRateHigh
        expr: sum(rate(klikkflow_workflow_executions_total{status="failed"}[5m])) / sum(rate(klikkflow_workflow_executions_total[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          service: klikkflow-backend
        annotations:
          summary: "High workflow execution failure rate"
          description: "Workflow execution failure rate is {{ $value | humanizePercentage }} for the last 5 minutes"

      - alert: WorkflowExecutionStuck
        expr: sum(klikkflow_workflow_executions_running) > 100
        for: 10m
        labels:
          severity: warning
          service: klikkflow-backend
        annotations:
          summary: "Too many running workflow executions"
          description: "There are {{ $value }} running workflow executions for more than 10 minutes"

      - alert: LongRunningExecution
        expr: klikkflow_workflow_execution_duration_seconds > 3600
        for: 0m
        labels:
          severity: warning
          service: klikkflow-backend
        annotations:
          summary: "Long running workflow execution detected"
          description: "Workflow execution {{ $labels.execution_id }} has been running for {{ $value | humanizeDuration }}"

      # Queue Alerts
      - alert: QueueBacklogHigh
        expr: klikkflow_queue_size{queue="workflow_execution"} > 1000
        for: 5m
        labels:
          severity: warning
          service: klikkflow-workers
        annotations:
          summary: "High queue backlog"
          description: "Workflow execution queue has {{ $value }} pending jobs"

      - alert: QueueProcessingStalled
        expr: rate(klikkflow_queue_processed_total[5m]) == 0 and klikkflow_queue_size > 0
        for: 5m
        labels:
          severity: critical
          service: klikkflow-workers
        annotations:
          summary: "Queue processing stalled"
          description: "Queue {{ $labels.queue }} has stopped processing jobs"

  - name: klikkflow.infrastructure
    rules:
      # Database Alerts
      - alert: MongoDBDown
        expr: up{job="mongodb"} == 0
        for: 1m
        labels:
          severity: critical
          service: mongodb
        annotations:
          summary: "MongoDB is down"
          description: "MongoDB has been down for more than 1 minute"

      - alert: PostgreSQLDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
          service: postgresql
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL has been down for more than 1 minute"

      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          service: redis
        annotations:
          summary: "Redis is down"
          description: "Redis has been down for more than 1 minute"

      # Database Performance
      - alert: MongoDBSlowQueries
        expr: rate(mongodb_op_counters_query[5m]) > 1000
        for: 5m
        labels:
          severity: warning
          service: mongodb
        annotations:
          summary: "MongoDB slow queries detected"
          description: "MongoDB query rate is {{ $value }} queries/second"

      - alert: MongoDBHighConnections
        expr: mongodb_connections{state="current"} / mongodb_connections{state="available"} > 0.8
        for: 5m
        labels:
          severity: warning
          service: mongodb
        annotations:
          summary: "MongoDB high connection usage"
          description: "MongoDB connection usage is {{ $value | humanizePercentage }}"

      # Cache Performance
      - alert: RedisHighMemoryUsage
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis high memory usage"
          description: "Redis memory usage is {{ $value | humanizePercentage }}"

      - alert: RedisSlowLog
        expr: increase(redis_slowlog_length[5m]) > 10
        for: 0m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis slow log entries detected"
          description: "{{ $value }} slow log entries in the last 5 minutes"

  - name: klikkflow.system
    rules:
      # System Resource Alerts
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: critical
          service: system
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 10
        for: 5m
        labels:
          severity: critical
          service: system
        annotations:
          summary: "Low disk space"
          description: "Disk space is {{ $value }}% available on {{ $labels.instance }}"

      - alert: HighDiskIOWait
        expr: irate(node_cpu_seconds_total{mode="iowait"}[5m]) * 100 > 30
        for: 5m
        labels:
          severity: warning
          service: system
        annotations:
          summary: "High disk I/O wait"
          description: "Disk I/O wait is {{ $value }}% on {{ $labels.instance }}"

      # Container Alerts
      - alert: ContainerHighCPUUsage
        expr: sum(rate(container_cpu_usage_seconds_total{name!=""}[5m])) by (name) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: containers
        annotations:
          summary: "Container high CPU usage"
          description: "Container {{ $labels.name }} CPU usage is {{ $value }}%"

      - alert: ContainerHighMemoryUsage
        expr: (container_memory_usage_bytes{name!=""} / container_spec_memory_limit_bytes{name!=""}) * 100 > 90
        for: 5m
        labels:
          severity: warning
          service: containers
        annotations:
          summary: "Container high memory usage"
          description: "Container {{ $labels.name }} memory usage is {{ $value }}%"

      - alert: ContainerRestartFrequent
        expr: increase(container_restart_count{name!=""}[1h]) > 5
        for: 0m
        labels:
          severity: warning
          service: containers
        annotations:
          summary: "Container restarting frequently"
          description: "Container {{ $labels.name }} has restarted {{ $value }} times in the last hour"

  - name: klikkflow.security
    rules:
      # Security Alerts
      - alert: SuspiciousRequestPattern
        expr: sum(rate(http_requests_total{code="403"}[5m])) by (instance) > 10
        for: 2m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "Suspicious request pattern detected"
          description: "High rate of 403 responses: {{ $value }} requests/second on {{ $labels.instance }}"

      - alert: FailedLoginAttempts
        expr: sum(rate(klikkflow_auth_failures_total[5m])) > 5
        for: 2m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "High number of failed login attempts"
          description: "{{ $value }} failed login attempts per second"

      - alert: UnauthorizedAPIAccess
        expr: sum(rate(http_requests_total{code="401"}[5m])) > 20
        for: 2m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "High unauthorized API access"
          description: "{{ $value }} unauthorized requests per second"

  - name: klikkflow.business
    rules:
      # Business Logic Alerts
      - alert: LowWorkflowCreationRate
        expr: sum(rate(klikkflow_workflows_created_total[1h])) < 1
        for: 1h
        labels:
          severity: info
          service: business
        annotations:
          summary: "Low workflow creation rate"
          description: "Only {{ $value }} workflows created in the last hour"

      - alert: CredentialTestFailures
        expr: sum(rate(klikkflow_credential_test_failures_total[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
          service: business
        annotations:
          summary: "Credential test failures detected"
          description: "{{ $value }} credential test failures per second"

      - alert: IntegrationDown
        expr: klikkflow_integration_health{status!="healthy"} == 1
        for: 5m
        labels:
          severity: warning
          service: integrations
        annotations:
          summary: "Integration health check failed"
          description: "Integration {{ $labels.integration }} is not healthy"