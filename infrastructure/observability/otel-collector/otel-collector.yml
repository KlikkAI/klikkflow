# OpenTelemetry Collector Configuration
# This configuration sets up a comprehensive telemetry data pipeline

receivers:
  # OTLP receiver for receiving telemetry data via gRPC and HTTP
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  # Prometheus receiver for scraping metrics from applications
  prometheus:
    config:
      scrape_configs:
        - job_name: 'reporunner-backend'
          static_configs:
            - targets: ['reporunner-backend:3001']
          scrape_interval: 15s
          metrics_path: /metrics

        - job_name: 'reporunner-frontend'
          static_configs:
            - targets: ['reporunner-frontend:3000']
          scrape_interval: 30s
          metrics_path: /metrics

        - job_name: 'reporunner-workers'
          static_configs:
            - targets: ['reporunner-worker:3002']
          scrape_interval: 15s
          metrics_path: /metrics

  # Jaeger receiver for receiving traces in Jaeger format
  jaeger:
    protocols:
      grpc:
        endpoint: 0.0.0.0:14250
      thrift_http:
        endpoint: 0.0.0.0:14268
      thrift_compact:
        endpoint: 0.0.0.0:6831
      thrift_binary:
        endpoint: 0.0.0.0:6832

  # Zipkin receiver for receiving traces in Zipkin format
  zipkin:
    endpoint: 0.0.0.0:9411

  # Fluentforward receiver for receiving logs from Fluent Bit/Fluentd
  fluentforward:
    endpoint: 0.0.0.0:24224

  # Host metrics receiver for system-level metrics
  hostmetrics:
    collection_interval: 10s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      disk:
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true
      network:
      load:
      processes:

  # Docker stats receiver for container metrics
  docker_stats:
    endpoint: unix:///var/run/docker.sock
    collection_interval: 10s
    timeout: 5s

  # Filelog receiver for reading log files
  filelog:
    include:
      - /var/log/reporunner/*.log
      - /var/lib/docker/containers/*/*.log
    include_file_name: false
    include_file_path: true
    operators:
      - type: json_parser
        id: parser-docker
        output: extract_metadata_from_filepath
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      - type: regex_parser
        id: extract_metadata_from_filepath
        regex: '^.*\/(?P<container_id>.+)\.log$'
        parse_from: attributes["log.file.path"]
        output: parse_body
      - type: move
        id: parse_body
        from: attributes.container_id
        to: resource["container.id"]

processors:
  # Batch processor to reduce the number of outgoing connections
  batch:
    timeout: 1s
    send_batch_size: 1024
    send_batch_max_size: 2048

  # Memory limiter to prevent OOM kills
  memory_limiter:
    limit_mib: 512
    spike_limit_mib: 128
    check_interval: 5s

  # Resource processor to add/modify resource attributes
  resource:
    attributes:
      - key: environment
        value: production
        action: upsert
      - key: service.namespace
        value: reporunner
        action: upsert
      - key: deployment.environment
        value: docker-compose
        action: upsert

  # Attributes processor to modify span/metric/log attributes
  attributes:
    actions:
      - key: container.id
        action: delete
      - key: sensitive_data
        action: delete
      - key: http.user_agent
        action: hash

  # Span processor for trace data modifications
  span:
    name:
      to_attributes:
        rules:
          - ^\/api\/(?P<api_version>v\d+)\/(?P<resource>\w+).*
      from_attributes: ["http.method", "http.route"]
      separator: " "

  # Metrics transform processor
  transform/metrics:
    metric_statements:
      - context: metric
        statements:
          - set(description, "Reporunner workflow execution duration") where name == "reporunner_workflow_execution_duration_seconds"
          - set(unit, "s") where name == "reporunner_workflow_execution_duration_seconds"

  # Probabilistic sampler for traces (reduces volume)
  probabilistic_sampler:
    hash_seed: 22
    sampling_percentage: 15.3

  # Tail sampling processor for intelligent trace sampling
  tail_sampling:
    decision_wait: 10s
    num_traces: 50000
    expected_new_traces_per_sec: 10
    policies:
      # Always sample errors
      - name: errors-policy
        type: status_code
        status_code:
          status_codes: [ERROR]
      # Always sample slow requests
      - name: latency-policy
        type: latency
        latency:
          threshold_ms: 5000
      # Sample a percentage of normal requests
      - name: probabilistic-policy
        type: probabilistic
        probabilistic:
          sampling_percentage: 10
      # Always sample specific services
      - name: reporunner-backend-policy
        type: string_attribute
        string_attribute:
          key: service.name
          values: [reporunner-backend, reporunner-worker]

  # Filter processor to drop unwanted telemetry data
  filter/logs:
    logs:
      exclude:
        match_type: regexp
        record_attributes:
          - key: log.level
            value: DEBUG
        bodies:
          - ".*health.*check.*"
          - ".*ping.*pong.*"

  filter/metrics:
    metrics:
      exclude:
        match_type: strict
        metric_names:
          - go_gc_duration_seconds_count
          - go_gc_duration_seconds_sum

exporters:
  # Jaeger exporter for traces
  jaeger:
    endpoint: jaeger:14250
    tls:
      insecure: true

  # Tempo exporter for traces (alternative to Jaeger)
  otlp/tempo:
    endpoint: tempo:4317
    tls:
      insecure: true

  # Zipkin exporter for traces
  zipkin:
    endpoint: http://zipkin:9411/api/v2/spans

  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: reporunner
    const_labels:
      environment: production

  # Elasticsearch exporter for logs and traces
  elasticsearch:
    endpoints: [http://elasticsearch:9200]
    logs_index: reporunner-logs
    traces_index: reporunner-traces
    mapping:
      mode: ecs
    timeout: 30s

  # Loki exporter for logs
  loki:
    endpoint: http://loki:3100/loki/api/v1/push
    default_labels_enabled:
      exporter: false
      job: true
    labels:
      attributes:
        service.name: "service_name"
        container.name: "container_name"
        log.level: "level"

  # OTLP exporter for sending to other OTEL collectors
  otlp/signoz:
    endpoint: signoz:4317
    tls:
      insecure: true

  # Debug exporter for troubleshooting
  debug:
    verbosity: basic
    sampling_initial: 5
    sampling_thereafter: 200

  # File exporter for backup/archival
  file:
    path: /tmp/otel-data.json
    rotation:
      max_megabytes: 100
      max_days: 3
      max_backups: 3

extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133

  # pprof extension for performance profiling
  pprof:
    endpoint: 0.0.0.0:1888

  # zpages extension for in-process diagnostics
  zpages:
    endpoint: 0.0.0.0:55679

  # Memory ballast extension to control memory usage
  memory_ballast:
    size_mib: 683

service:
  extensions: [health_check, pprof, zpages, memory_ballast]

  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp, jaeger, zipkin]
      processors: [memory_limiter, resource, attributes, span, probabilistic_sampler, tail_sampling, batch]
      exporters: [jaeger, otlp/tempo, zipkin, otlp/signoz, debug]

    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics, docker_stats]
      processors: [memory_limiter, resource, transform/metrics, filter/metrics, batch]
      exporters: [prometheus, otlp/signoz, debug]

    # Logs pipeline
    logs:
      receivers: [otlp, fluentforward, filelog]
      processors: [memory_limiter, resource, attributes, filter/logs, batch]
      exporters: [elasticsearch, loki, otlp/signoz, debug]

  # Telemetry configuration for the collector itself
  telemetry:
    logs:
      level: info
      development: false
      sampling:
        enabled: true
        tick: 10s
        initial: 5
        thereafter: 200
      encoding: json
    metrics:
      level: basic
      readers:
        - pull:
            exporter:
              prometheus:
                host: 0.0.0.0
                port: 8888
    traces:
      processors:
        - batch:
            exporter:
              otlp:
                endpoint: tempo:4317